/*
  Inart Detail Page Scraper
  - Reads existing inart-ì†ŒíŒŒ.json from data/ì¸ì•„íŠ¸/
  - For each product, visits the detail page and extracts ONE detail image
  - Outputs: Updates inart-ì†ŒíŒŒ.json with detail image
*/

const fs = require('fs');
const path = require('path');
const { chromium } = require('playwright');

const DATA_DIR = path.join(process.cwd(), 'data', 'ì¸ì•„íŠ¸');
const CATEGORY_FILES = [
  'inart-ì†ŒíŒŒ.json',
  'inart-ì˜·ì¥, ìˆ˜ë‚©ì¥.json',
  'inart-ì˜ì.json',
  'inart-ì¹¨ëŒ€.json',
  'inart-í…Œì´ë¸”.json'
];
const DELAY_BETWEEN_PRODUCTS = 1500; // 1.5ì´ˆ
const DELAY_BETWEEN_CATEGORIES = 3000; // 3ì´ˆ
const MAX_RETRIES = 3;

async function scrapeProductDetail(page, productUrl, productTitle) {
  console.log(`  â†’ Scraping: ${productTitle}`);

  try {
    await page.goto(productUrl, { waitUntil: 'domcontentloaded', timeout: 30000 });
    await page.waitForTimeout(1000 + Math.random() * 1000);

    // ìƒì„¸ ì´ë¯¸ì§€ í•˜ë‚˜ë§Œ ì°¾ê¸° (godohosting.com ë„ë©”ì¸ì˜ ì´ë¯¸ì§€)
    const detailImage = await page.$$eval(
      'img',
      (imgs) => {
        for (let img of imgs) {
          let src = img.src || img.getAttribute('data-src') || img.getAttribute('data-original');

          // godohosting.com ë„ë©”ì¸ ì´ë¯¸ì§€ë§Œ ì°¾ê¸°
          if (src && src.includes('godohosting.com')) {
            // icon, logo, btn ë“±ì€ ì œì™¸
            if (src.includes('icon') || src.includes('logo') || src.includes('btn')) continue;
            if (src.includes('arrow') || src.includes('nav') || src.includes('menu')) continue;
            if (src.includes('list')) continue; // ë¦¬ìŠ¤íŠ¸ ì´ë¯¸ì§€ ì œì™¸

            return src;
          }
        }
        return null;
      }
    ).catch(() => null);

    console.log(`    âœ“ Detail image: ${detailImage ? 'Found' : 'Not found'}`);

    return {
      detailImage: detailImage || '',
      scrapedAt: new Date().toISOString()
    };

  } catch (error) {
    console.error(`    âœ— Failed to scrape: ${error.message}`);
    return null;
  }
}

async function processCategory(browser, categoryFile) {
  const filePath = path.join(DATA_DIR, categoryFile);

  if (!fs.existsSync(filePath)) {
    console.log(`âš  File not found: ${categoryFile}`);
    return { scrapedCount: 0, errorCount: 0 };
  }

  const products = JSON.parse(fs.readFileSync(filePath, 'utf8'));
  console.log(`\nğŸ“¦ Processing: ${categoryFile} (${products.length} products)`);

  // Check how many already have detail data
  const withDetails = products.filter(p => p.detailImage).length;
  console.log(`   Already scraped: ${withDetails}/${products.length}`);

  const page = await browser.newPage();
  await page.setViewportSize({ width: 1366, height: 768 });

  // Anti-detection
  await page.addInitScript(() => {
    Object.defineProperty(navigator, 'webdriver', { get: () => false });
    Object.defineProperty(navigator, 'languages', { get: () => ['ko-KR', 'ko', 'en-US'] });
  });

  let scrapedCount = 0;
  let errorCount = 0;

  for (let i = 0; i < products.length; i++) {
    const product = products[i];

    // Skip if already has detail data
    if (product.detailImage) {
      console.log(`  â­ Skipping (already scraped): ${product.title}`);
      continue;
    }

    if (!product.productUrl) {
      console.log(`  âš  No URL for: ${product.title}`);
      continue;
    }

    let detailData = null;
    let retries = 0;

    while (!detailData && retries < MAX_RETRIES) {
      detailData = await scrapeProductDetail(page, product.productUrl, product.title);
      if (!detailData) {
        retries++;
        if (retries < MAX_RETRIES) {
          console.log(`    â†» Retry ${retries}/${MAX_RETRIES}...`);
          await page.waitForTimeout(2000 * retries);
        }
      }
    }

    if (detailData) {
      // Update product with detail data
      products[i] = { ...product, ...detailData };
      scrapedCount++;
      console.log(`    âœ“ Success (${scrapedCount} total)`);
    } else {
      errorCount++;
      console.log(`    âœ— Failed after ${MAX_RETRIES} retries`);
    }

    // Auto-save every 10 products
    if ((i + 1) % 10 === 0 || i === products.length - 1) {
      fs.writeFileSync(filePath, JSON.stringify(products, null, 2), 'utf8');
      console.log(`    ğŸ’¾ Saved progress: ${i + 1}/${products.length}`);
    }

    // Delay between products
    await page.waitForTimeout(DELAY_BETWEEN_PRODUCTS + Math.random() * 1000);
  }

  await page.close();

  console.log(`âœ… ${categoryFile} complete:`);
  console.log(`   Scraped: ${scrapedCount}, Errors: ${errorCount}, Total: ${products.length}`);

  return { scrapedCount, errorCount };
}

(async () => {
  console.log('ğŸš€ Starting Inart Detail Scraper...\n');
  console.log(`ğŸ“‚ Processing ${CATEGORY_FILES.length} categories\n`);

  const browser = await chromium.launch({
    headless: true,
    args: ['--no-sandbox', '--disable-setuid-sandbox']
  });

  let totalScraped = 0;
  let totalErrors = 0;

  for (let i = 0; i < CATEGORY_FILES.length; i++) {
    const categoryFile = CATEGORY_FILES[i];
    console.log(`\n[${i + 1}/${CATEGORY_FILES.length}] ğŸ“ ${categoryFile}`);

    const result = await processCategory(browser, categoryFile);
    totalScraped += result.scrapedCount;
    totalErrors += result.errorCount;

    // Delay between categories
    if (i < CATEGORY_FILES.length - 1) {
      console.log(`\nâ³ Waiting ${DELAY_BETWEEN_CATEGORIES}ms before next category...`);
      await new Promise(resolve => setTimeout(resolve, DELAY_BETWEEN_CATEGORIES));
    }
  }

  await browser.close();

  console.log('\nğŸ‰ All categories complete!');
  console.log(`ğŸ“Š Total scraped: ${totalScraped}`);
  console.log(`âŒ Total errors: ${totalErrors}`);
})();
